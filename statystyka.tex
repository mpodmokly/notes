\documentclass[11pt, leqno]{scrartcl}
\usepackage{polski}
\usepackage[polish]{babel}

\usepackage{graphicx, float, caption, subcaption}
\usepackage{tabularx, multirow, hyperref, enumitem}
\usepackage{listings, xcolor}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=black,
    citecolor=black
}

\newtheoremstyle{mydefinition}
    {1.2em}{1.2em}{}{}{\bfseries}{}{0pt}
    {\thmname{#1} \thmnumber{#2.}\thmnote{ #3.}\\[0.5em]}
\theoremstyle{mydefinition}
\newtheorem{definition}{Definicja}[subsection]

\newtheoremstyle{mytheorem}
    {1.2em}{1.2em}{}{}{\bfseries}{}{0pt}
    {\thmname{#1} \thmnumber{#2.}\thmnote{ #3.}\\[0.5em]}
\theoremstyle{mytheorem}
\newtheorem{theorem}{Twierdzenie}[subsection]

\makeatletter
\renewcommand{\thebibliography}[1]{%
  \list{\@biblabel{\@arabic\c@enumiv}}%
       {\settowidth\labelwidth{\@biblabel{#1}}%
        \leftmargin\labelwidth
        \advance\leftmargin\labelsep
        \usecounter{enumiv}%
        \let\p@enumiv\@empty
        \renewcommand\theenumiv{\@arabic\c@enumiv}}%
  \sloppy\clubpenalty4000\widowpenalty4000%
  \sfcode`\.=1000\relax}
\makeatother

\graphicspath{{images/}}

\title{Rachunek prawdopodobieństwa i statystyka}
\author{Mateusz Podmokły III rok Informatyka WI}
\date{semestr zimowy 2025}

\begin{document}
    \maketitle
    \tableofcontents
    \newpage

    \section{Podstawy rachunku prawdopodobieństwa}
    \subsection{Przestrzeń probabilistyczna}
    \begin{definition}[Przestrzeń zdarzeń elementarnych]
        Niepusty zbiór $\Omega$ wszystkich możliwych wyników
        doświadczenia losowego. Jego elementy to zdarzenia elementarne.
    \end{definition}
    \begin{definition}[$\sigma$-algebra zdarzeń]
        Podrodzina $\Sigma$ w rodzinie wszystkich podzbiorów $\Omega$
        o następujących właściwościach:
        \begin{enumerate}
            \item $\Omega \in \Sigma$
            \item Jeśli $A \in \Sigma$ to $A'=\Omega \setminus A \in
                \Sigma$
            \item Dla dowolnego ciągu zbiorów $A_1,A_2,\ldots$ takiego,
                że $A_i \in \Sigma$ dla $i \in \mathbb{N}$, zachodzi
                \[
                    \bigcup_{i=1}^{\infty}A_i \in \Sigma
                \]
        \end{enumerate}
        Jej elementy to zdarzenia losowe.
    \end{definition}
    \noindent
    Własności zdarzeń:
    \begin{enumerate}
        \item $\emptyset \in \Sigma$
        \item Jeśli $A_1,A_2,\ldots,A_n \in \Sigma$, to
            $A_1 \cup A_2 \cup \ldots \cup A_n \in \Sigma$
        \item Dla dowolnego ciągu $A_1,A_2,\ldots$ takiego, że
            $A_i \in \Sigma$ dla $i \in \mathbb{N}$, zachodzi
            \[
                \bigcap_{i=1}^{\infty}A_i \in \Sigma
            \]
        \item Jeśli $A,B \in \Sigma$ to $A \setminus B \in \Sigma$
    \end{enumerate}
    Określmy niezbędną terminologię:
    \begin{description}
        \item[$\emptyset$] -- zdarzenie niemożliwe
        \item[$\Omega$] -- zdarzenie pewne
        \item[$A'=\Omega \setminus A$] -- dopełnienie zdarzenia $A$
        \item[$A \cap B= \emptyset$] -- zdarznia wzajemnie się
            wykluczają.
    \end{description}
    \begin{definition}[Miara probabilistyczna (rozkładbprawdopodobieństwa)]
        W przestrzeni $\Omega$ z $\sigma$-algebrą zdarzeń $\Sigma$
        dowolne odwzorowanie
        \[
            P:\Sigma \to [0,1]
        \]
        spełniające warunki:
        \begin{enumerate}
            \item $P(\Omega)=1$
            \item Dla dowolnego ciągu zdarzeń $A_1,A_2,\ldots$ takiego,
                że $A_i \in \Sigma$ dla $i \in \mathbb{N}$ oraz
                $A_i \cap A_j=\emptyset$ dla $i \neq j$ zachodzi
                \[
                    P\left(\bigcup_{i=1}^{\infty}A_i\right)=
                    \sum_{i=1}^{\infty}P(A_i)
                \]
        \end{enumerate}
    \end{definition}
    Własności prawdopodobieństwa:
    \begin{enumerate}
        \item $P(\emptyset)$=0
        \item Jeśli skończony ciąg zdarzeń $A_1,A_2,\ldots,A_n$ spełnia
            warunek
            \[
                A_i \cap A_j = \emptyset \text{ dla }i \neq j
            \]
            to
            \[
                P(A_1 \cup A_2 \cup \ldots \cup A_n)=
                P(A_1)+P(A_2)+\ldots +P(A_n)
            \]
        \item Dla dowolnego zdarzenia $A$ zachodzi
            \[
                P(A')=1-P(A)
            \]
        \item Dla dowolnych zdarzeń $A$ i $B$ zachodzi
            \[
                P(A \cup B)=P(A)+P(B)-P(A \cap B)
            \]
        \item Jeśli $A \subset B$ to $P(A)\leq P(B)$
        \item Jeśli zdarzenia $A_1,A_2,\ldots$ tworzą ciąg
            wstępujący, tzn.
            \[
                A_1 \subset A_2 \subset \ldots
            \]
            to
            \[
                P\left( \bigcup_{i=1}^{\infty}A_i \right)=
                \lim_{i \to \infty}P(A_i)
            \]
        \item Jeśli zdarzenia $A_1,A_2,\ldots$ tworzą ciąg
            zstępujący, tzn.
            \[
                A_1 \supset A_2 \supset \ldots
            \]
            to
            \[
                P\left( \bigcap_{i=1}^{\infty}A_i \right)=
                \lim_{i \to \infty}P(A_i)
            \]
    \end{enumerate}
    \begin{definition}[Przestrzeń probabilistyczna]
        Trójka $(\Omega,\Sigma,P)$, gdzie:
        \begin{description}
            \item[$\Omega$] -- niepusty zbiór,
            \item[$\Sigma$] -- $\sigma$-algebra w $\Omega$,
            \item[$P$] -- miara probabilistyczna.
        \end{description}
    \end{definition}
    Liczbę $P(A)$ nazywamy prawdopodobieństwem zdarzenia $A$.

    \subsection{Prawdopodobieństwo warunkowe}
    \begin{definition}[Prawdopodobieństwo warunkowe]
        Liczba określona wzorem
        \[
            P(A \mid B)=\frac{P(A \cap B)}{P(B)}
        \]
        gdzie
        \begin{description}
            \item[$A,B \subset \Omega$] -- zdarzenia,
            \item[$P(B)>0$.]
        \end{description}
        Jest to prawdopodobieństwo $A$ pod warunkiem $B$.
    \end{definition}
    \begin{definition}[Układ zupełny zdarzeń]
        Skończony lub nieskończony ciąg zdarzeń $A_1,A_2,\ldots$ jeśli
        zdarzenia w ciągu parami wzajemnie się wykluczają, tzn.
        \[
            A_i \cap A_j =\emptyset, \quad i \neq j
        \]
        oraz zachodzi
        \[
            \Omega=\bigcup_{i}A_i
        \]
    \end{definition}
    \begin{theorem}[Twierdzenie o prawdopodobieństwie całkowitym]
        Jeśli zdarzenia $A_1,A_2,\ldots$ tworzą układ zupełny oraz
        $P(A_i)>0$ dla $i \in \mathbb{N}$, to dla dowolnego
        zdarzenia $B$ zachodzi
        \[
            P(B)=\sum_{i}P(B \mid A_i)P(A_i)
        \]
    \end{theorem}
    \begin{theorem}[Twierdzenie Bayesa]
        Jeśli zdarzenia $A_i$ tworzą układ zupełny taki, że
        $P(A_i)>0$ dla $i \in \mathbb{N}$, a $B$ jest zdarzeniem
        takim, że $P(B)>0$, to dla dowolnego $k$ zachodzi
        \[
            P(A_k \mid B)=\frac{P(B \mid A_k)P(A_k)}
            {\sum_{i}P(B \mid A_i)P(A_i)}
        \]
    \end{theorem}
    
    \subsection{Niezależność zdarzeń}
    \begin{definition}[Niezależność zdarzeń]
        Zdarzenia $A$ i $B$ nazywamy niezależnymi jeśli
        \[
            P(A,B)=P(A) \cdot P(B)
        \]
        Zdarzenia $A_1,A_2,\ldots,A_k$ nazywamy niezależnymi jeśli dla
        każdego układu indeksów $i_1,i_2,\ldots,i_k$ oraz dla każdego
        $k \in \{1,2,\ldots,m\}$ zachodzi
        \[
            P(A_{i_1},A_{i_2},\ldots,A_{i_k})=P(A_{i_1}) \cdot
            P(A_{i_2}) \cdot \ldots \cdot P(A_{i_k})
        \]
    \end{definition}
    \begin{definition}[Niezależność warunkowa]
        Zdarzenia $A$ i $B$ są warunkowo niezależne względem $C$
        dla $P(C)>0$ jeśli
        \[
            P(A,B \mid C)=P(A \mid C) \cdot P(B \mid C)
        \]
        Zdarzenia $A_1,A_2,\ldots,A_k$ są warunkowo niezależne względem $C$ dla
        $P(C)>0$ jeśli dla każdego układu indeksów $i_1,i_2,\ldots,i_k$ oraz dla
        każdego $k \in \{1,2,\ldots,m\}$ zachodzi
        \[
            P(A_{i_1},A_{i_2},\ldots,A_{i_k} \mid C)=P(A_{i_1} \mid C) \cdot
            P(A_{i_2} \mid C) \cdot \ldots \cdot P(A_{i_k} \mid C)
        \]
    \end{definition}

    \section{Zmienne losowe jednowymiarowe}
    \subsection{Zmienna losowa}
    \begin{definition}[Zmienna losowa]
        Zmienna losowa to odwzorowanie
        \[
            X:\Omega \to \mathcal{X}
        \]
        takie, że dla każdego $A \in \Sigma_{\mathcal{X}}$ zachodzi
        \[
            X^{-1}(A) \in \Sigma
        \]
        gdzie $(\Omega,\Sigma,P)$ jest przestrzenią probabilistyczną,
        $\mathcal{X}$ dowolnym niepustym zbiorem, a $\Sigma_{\mathcal{X}}$
        $\sigma$-algebrą podzbiorów $\mathcal{X}$.
    \end{definition}
    \begin{definition}[Rozkład prawdopodobieństwa zmiennej losowej]
        Funkcję
        \[
            P_X:\Sigma_{\mathcal{X}} \to [0,1]
        \]
        określoną następująco
        \[
            P_X(A)=P(X^{-1}(A))
        \]
        gdzie $(\Omega,\Sigma,P)$ jest przestrzenią probabilistyczną,
        $\mathcal{X}$ niepustym zbiorem, $\Sigma_{\mathcal{X}}$
        $\sigma$-algebrą w $\mathcal{X}$, a $X:\Omega \to \mathcal{X}$
        zmienną losową.
    \end{definition}

    \subsection{Zmienne losowe rzeczywiste}
    \begin{definition}[Dystrybuanta zmiennej losowej]
        Niech $X:\Omega \to \mathbb{R}$ będzie zmienną losową rzeczywistą.
        Dystrybuantą zmiennej losowej rzeczywistej $X$ nazywamy funkcję
        \[
            F_X:\mathbb{R} \to [0,1]
        \]
        określoną wzorem
        \[
            F_X(x)=P(X \leq x)=P_X((-\infty,x])
        \]
    \end{definition}
    \noindent
    Własności dystrybuanty:
    \begin{enumerate}
        \item Jeśli $a<b$, to $F_X(b)-F_X(a)=P(a<X \leq b)$
        \item $F_X$ jest niemalejąca
        \item $\lim\limits_{x \to -\infty}F_X(x)=0$
            i $\lim\limits_{x \to +\infty}F_X(x)=1$
        \item $F_X$ jest prawostronnie ciągła, tzn. dla dowolnego
            $x_0 \in \mathbb{R}$ zachodzi
            \[
                \lim_{x \to x_0^+}F_X(x)=F_X(x_0)
            \]
        \item $F_X(x_0-)=\lim\limits_{x \to x_0^-}F_X(x)=P(X<x_0)$
        \item $P(X=x)=F_X(x)-F_X(x-)$
        \item $F_X$ jest ciągła w $x_0 \in \mathbb{R}$ wtedy i tylko
            wtedy, gdy
            \[
                P(X=x_0)=0
            \]
    \end{enumerate}
    \begin{definition}[Funkcja prawdopodobieństwa]
        Rozkład dyskretny zmiennej $X$ jest wyznaczony przez funkcję
        \[
            p:\mathcal{S} \to [0,1]
        \]
        określoną następująco:
        \[
            p(x_k)=P_X(x_k)=P(X=x_k)
        \]
        Funkcję $p$ nazywamy funkcją prawdopodobieństwa rozkładu zmiennej $X$.
    \end{definition}
    \begin{definition}[Funkcja gęstości]
        Gęstość zmiennej losowej $X$ to funkcja
        \[
            f:\mathbb{R} \to [0,+\infty)
        \]
        taka, że dla dowolnych $a,b\in \mathbb{R} \cup \{-\infty,+\infty\}$
        takich, że $a<b$ zachodzi
        \[
            P(a<X<b)=\int_{a}^{b}f(x)dx
        \]
    \end{definition}

    \subsection{Parametry zmiennej losowej}
    \begin{definition}[Wartość oczekiwana]
        Wartością oczekiwaną zmiennej losowej rzeczywistej $X$ o rozkładzie
        dyskretnym z funkcją prawdopodobieństwa $p$ nazywamy liczbę określoną
        wzorem
        \[
            \mu=\mathbb{E}(X)=\sum_{x_k \in \mathcal{S}}
            x_k \cdot p(x_k)
        \]
        Jeśli $X$ jest zmienną o rozkładzie ciągłym z gęstością $f$, to
        \[
            \mu =\int_{-\infty}^{\infty}xf(x)dx
        \]
    \end{definition}
    \noindent
    Własności wartości oczekiwanej:
    \begin{enumerate}
        \item $\mathbb{E}c=c$
        \item $\mathbb{E}(aX+bY+c)=a\mathbb{E}X+b\mathbb{E}Y+c$
        \item Dla rozkładów ciągłych
            \[
                \mathbb{E}(g(X))=\int_{-\infty}^{\infty}g(x)f(x)dx
            \]
            dla rozkładów dyskretnych
            \[
                \mathbb{E}(g(X))=\sum_{x_k\in\mathcal{S}}g(x_k)f(x_k)dx
            \]
    \end{enumerate}
    \begin{definition}[Moment zwykły]
        Momentem zwykłym rzędu $k$ zmiennej losowej $X$ dla
        $k \in \mathbb{N} \setminus \{0\}$ nazywamy liczbę
        \[
            \mu'_k=\mathbb{E}(X^k)
        \]
    \end{definition}
    \begin{definition}[Moment centralny]
        Momentem centralnym rzędu $k$ zmiennej losowej $X$ nazywamy liczbę
        \[
            \mu_k=\mathbb{E}((X-\mu)^k)
        \]
    \end{definition}
    \noindent
    Dla rozkładów dyskretnych
    \[
        \mu'_k=\sum_{i:x_i\in \mathcal{S}}x_i^k \cdot p(x_i)
    \]
    \[
        \mu_k=\sum_{i:x_i\in \mathcal{S}}(x_i-\mu)^k \cdot p(x_i)
    \]
    Dla rozkładów ciągłych
    \[
        \mu'_k=\int_{-\infty}^{\infty}x^kf(x)dx
    \]
    \[
        \mu_k=\int_{-\infty}^{\infty}(x-\mu)^kf(x)dx
    \]
    \begin{definition}[Wariancja]
        Wariancją zmiennej losowej $X$ nazywamy jej drugi moment centralny, tzn.
        \[
            Var(X)=\sigma^2=\mu_2=\mathbb{E}((X-\mu)^2)
        \]
    \end{definition}
    \noindent
    Własności wariancji:
    \begin{enumerate}
        \item $Var(X)=\mathbb{E}(X^2)-(\mathbb{E}X)^2$
        \item Jeśli zmienna $X$ ma skończoną wariancję, to dla dowolnych
            $a,b\in \mathbb{R}$ zachodzi
            \[
                Var(aX+b)=a^2Var(X)
            \]
        \item $Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)$
        \item $Var(X)=0$ wtedy i tylko wtedy, gdy $X$ jest stała
            z prawdopodobieństwem 1, tzn. istnieje $x_0\in \mathbb{R}$
            takie, że
            \[
                P(X \neq x_0)=0
            \]
    \end{enumerate}
    \begin{definition}[Odchylenie standardowe]
        Odchyleniem standardowym zmiennej losowej $X$ nazywamy pierwiastek jej
        wariancji, tzn.
        \[
            \sigma=\sqrt{Var(X)}
        \]
    \end{definition}
    \begin{definition}[Funkcja tworząca momenty (MGF)]
        Funkjcą tworzącą momenty rzeczywistej zmiennej losowej $X$
        nazywa się funkcję określoną wzorem
        \[
            M_X(t)=\mathbb{E}\left(e^{tX}\right)
        \]
    \end{definition}
    Jeśli $X$ ma rozkład dyskretny z funkcją prawdopodobieństwa $p$, to funkcja
    tworząca momenty wyraża się wzorem
    \[
        M_X(t)=\sum_{x_k\in \mathcal{S}}e^{tx_k}p(x_k)
    \]
    Jeśli $X$ ma rozkład ciągły o gęstości $f$, to funkcja tworząca momenty ma
    postać
    \[
        M_X(t)=\int_{-\infty}^{+\infty}e^{tx}f(x)dx
    \]
    Niech $a,b \in \mathbb{R}$. Własności MGF:
    \begin{enumerate}
        \item $M_{aX}(t)=M_X(at)$
        \item $M_{X+b}(t)=e^{bt}M_X(t)$
        \item $M_{aX+b}(t)=e^{bt}M_X(at)$
        \item $M^{(k)}(0)=\mathbb{E}(X^k)$
    \end{enumerate}
    \begin{definition}[Współczynnik asymetrii (skośność)]
        Współczynnikiem skośności rozkładu zmiennej $X$ nazywamy liczbę
        \[
            A=\gamma_1=\frac{\mu_3}{\sigma^3}
        \]
        Rozkład, dla którego:
        \begin{itemize}
            \item $A=0$ nazywa się \textbf{symetrycznym}
            \item $A>0$ nazywa się \textbf{prawostronnie skośnym}
            \item $A<0$ nazywa się \textbf{lewostronnie skośnym}
        \end{itemize}
    \end{definition}
    \begin{definition}[Kurtoza]
        Kurtozą nazywamy liczbę
        \[
            Kurt(X)=K=\frac{\mu_4}{\sigma^4}
        \]
        natomiast \textbf{kurtozą nadwyżkową} nazywamy liczbę
        \[
            \gamma_3=Kurt(X)-3
        \]
    \end{definition}
    \begin{definition}[Standaryzacja]
        Zmienną o wartości średniej 0 i wariancji 1 nazywa się zmienną
        standaryzowaną. Jeśli $X$ jest dowolną zmienną o niezerowej wariancji, to
        \[
            Z=\frac{X-\mu}{\sigma}
        \]
        jest zmienną standaryzowaną.
    \end{definition}
    \begin{theorem}[Nierówność Czebyszewa]
        Jeśli zmienna losowa $X$ ma skończoną wartość średnią $\mu$ i skończoną
        wariancję $\sigma^2$, to dla dowolnego $\epsilon>0$ zachodzi
        \[
            P(|X-\mu|\geq \epsilon) \leq \frac{\sigma^2}{\epsilon^2}
        \]
        Jeśli w miejsce $\epsilon$ podstawimy $\epsilon \sigma$, to otrzymamy
        \[
            P(|X-\mu|\geq \epsilon \sigma) \leq \frac{1}{\epsilon^2}
        \]
    \end{theorem}
    \begin{definition}[Kwantyl]
        Kwantylem rzędu $p\in (0,1)$ zmiennej losowej $X$ o dystrybuancie
        $F$ nazywamy dowolną liczbę $q_p \in \mathbb{R}$ taką, że
        \[
            F(q_p-) \leq p \leq F(q_p)
        \]
        Kwantyl $q_{0.5}$ rzędu $\frac{1}{2}$ nazywamy \textbf{medianą}, kwantyl
        rzędu $\frac{1}{4}$ nazywamy \textbf{dolnym kwartylem}, a kwantyl rzędu
        $\frac{3}{4}$ nazywamy \textbf{górnym kwartylem}.
    \end{definition}
    Jeśli $X$ ma rozkład ciągły, to kwantylem $q_p$ rzędu $p$ jest dowolne
    $q_p$ spełniające równanie
    \[
        F(q_p)=p
    \]
    \begin{definition}[Moda]
        Modą zmiennej losowej o rozkładzie dyskretnym nazywa się dowolne
        maksimum funkcji prawdopodobieństwa tego rozkładu. Jeżeli zmienna ma
        rozkład ciągły to modą jest dowolne maksimum lokalne gęstości tego
        rozkładu.
    \end{definition}

    \subsection{Funkcje zmiennych losowych}
    \begin{theorem}[Metoda transformacji]
        Jeśli $Y=g(X)$ oraz $g$ jest fukcją ściśle monotoniczną, to istnieje
        funkcja odwrotna
        \[
            h=g^{-1}
        \]
        jeśli funkcja $h$ jest różniczkowalna, to gęstość rozkładu $Y$ spełnia
        następującą równość
        \[
            f_Y(y)=f_X(h(y)) \cdot |h'(y)|
        \]
    \end{theorem}
    \noindent
    Ważne szczególne przypadki dla rozkładów jednowymiarowych. Załóżmy, że
    $c\neq 0$ i $d\in\mathbb{R}$:
    \begin{enumerate}
        \item Jeśli $X \sim \mathcal{N}(\mu,\sigma)$ i $Y=cX+d$, to
            \[
                Y \sim \mathcal{N}(c\mu +d,|c|\sigma)
            \]
        \item Jeśli $X \sim \mathcal{U}(a,b)$ i $Y=cX+d$, to
            \[
                Y \sim
                \begin{cases}
                    \mathcal{U}(ca+d,cb+d) & ,c>0 \\
                    \mathcal{U}(cb+d,ca+d) & ,c<0
                \end{cases}
            \]
        \item Jeśli $X \sim Gamma(s,r)$ i $Y=cX$ dla $c>0$, to
            \[
                Y \sim Gamma\left(s, \frac{r}{c}\right)
            \]
    \end{enumerate}
    
    \section{Wybrane rozkłady prawdopodobieństwa}
    \subsection{Rozkłady dyskretne}
    \begin{definition}[Rozkład jednopunktowy]
        Jeśli $\mathcal{S}=\{x_0\}$ i $p(x_0)=1$, to mówimy, że zmienna losowa
        ma \textbf{rozkład jednopunktowy}. Wtedy przyjmuje parametry:
        \[
            \mu=x_0
        \]
        \[
            \sigma^2=0
        \]
        \[
            A=0
        \]
        \[
            K=0
        \]
        \[
            \gamma_2=-3
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{jednopunktowy.png}
            \caption{Funkcja prawdopodobieństwa w rozkładzie
                jednopunktowym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład dwupunktowy]
        Jeśli
        \[
            \mathcal{S}=\{x_1,x_2\}
        \]
        oraz
        \[
            p(x_1)=\theta
        \]
        \[
            p(x_2)=1-\theta
        \]
        dla pewnego $\theta \in (0,1)$, to mówimy, że zmienna losowa ma
        \textbf{rozkład dwupunktowy} z parametrem $\theta$. Wtedy
        przyjmuje parametry:
        \[
            \mu=\theta x_1+(1-\theta)x_2
        \]
        \[
            \sigma^2=\theta(1-\theta)(x_1-x_2)^2
        \]
        \[
            A=sgn(x_1-x_2)\frac{1-2\theta}{\sqrt{\theta(1-\theta)}}
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{dwupunktowy.png}
            \caption{Funkcja prawdopodobieństwa w rozkładzie
                dwupunktowym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład Bernoulli'ego]
        Rozkład dwupunktowy, w którym $x_1=1$ i $x_2=0$ nazywa się
        \textbf{rozkładem Bernoulli'ego} z parametrem $\theta$
        \[
            X \sim Bern(\theta)
        \]
        Wówczas
        \[
            \mu=\theta
        \]
        \[
            \sigma^2=\theta(1-\theta)
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{bernoulliego.png}
            \caption{Funkcja prawdopodobieństwa w rozkładzie
                Bernoulli'ego.}
        \end{figure}
    \end{definition}
    \begin{definition}[Dyskretny rozkład jednostajny]
        Jeśli $\mathcal{S}=\{x_1,x_2,\ldots,x_n\}$ i $p(x_i)=\frac{1}{n}$
        dla każdego $i \in \{1,2,\ldots,n\}$, to mówimy, że zmienna
        losowa ma \textbf{dyskretny rozkład jednostajny} na $n$ punktach.
        Wówczas
        \[
            \mu=\frac{1}{n}\sum_{i=1}^{n}x_i
        \]
        \[
            \sigma^2=\frac{1}{n}\sum_{i=1}^{n}(x_i-\mu)^2
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]
                {jednostajny_dyskretny.png}
            \caption{Funkcja prawdopodobieństwa w dyskretnym rozkładzie
                jednostajnym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Próba Bernoulli'ego]
        Rozważmy doświadczenie losowe o dwu możliwych wynikach:
        \begin{itemize}
            \item \textbf{sukces} z prawdopodobieństwem
                $\theta \in (0,1)$
            \item \textbf{porażka} z prawdopodobieństwem $1-\theta$
        \end{itemize}
        Doświadczenie tego rodzaju nazywamy
        \textbf{próbą Bernoulli'ego}.
    \end{definition}
    \begin{definition}[Schemat dwumianowy]
        Schemat doświadczenia określony jako n-krotne powtórzenie próby
        Bernoulli'ego w ten sposób, że poszczególne próby są niezależne.
        Długość schematu może być skończona lub nieskończona.
    \end{definition}
    \begin{definition}[Rozkład dwumianowy]
        Niech $X$ będzie zmienną losową, której wartością jest liczba
        sukcesów w schemacie dwumianowym o długości $n$ z prawdopodobieństwem
        sukcesu $\theta$. Wówczas $X$ ma rozkład dyskretny, w którym
        \[
            \mathcal{S}=\{0,1,\ldots,n\}
        \]
        oraz
        \[
            p(k)=\binom{n}{k}\theta^k(1-\theta)^{n-k}
        \]
        Jeśli zmienna $X$ ma rozkład dwumianowy o parametrach $n\in \mathbb{N}$
        i $\theta \in (0,1)$, to zapisujemy
        \[
            X \sim Binom(n,\theta)
        \]
        oraz
        \[
            \mu=n\theta
        \]
        \[
            \sigma^2=n\theta(1-\theta)
        \]
        Łatwo zauważyć, że
        \[
            Binom(1,\theta)=Bern(\theta).
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{dwumianowy.png}
            \caption{Funkcja prawdopodobieństwa w rozkładzie dwumianowym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład geometryczny]
        Zmienna losowa $T$ ma rozkład geometryczny z parametrem
        $\theta \in (0,1)$
        \[
            T \sim Geom(\theta),
        \]
        jeśli
        \[
            \mathcal{S}=\mathbb{N}\setminus \{0\},
        \]
        a funkcja prawdopodobieństwa ma postać
        \[
            p(k)=(1-\theta)^{k-1}\theta
        \]
        \[
            k\in\mathcal{S}
        \]
        Zmienna $T$ opisuje czas oczekiwania na pierwszy sukces w schemacie
        dwumianowym (o nieskończonej długości). Wówczas
        \[
            \mu=\frac{1}{\theta}
        \]
        \[
            \sigma^2=\frac{1-\theta}{\theta^2}
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{geometryczny.png}
            \caption{Funkcja prawdopodobieństwa w rozkładzie geometrycznym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład Poissona]
        Jeśli zmienna $N$ o wartościach w $\mathbb{N}$ opisuje liczbę wystąpień
        pewnego powtarzalnego zdarzenia w przedziale czasowym $[0,t]$, przy
        czym spełnione są założenia:
        \begin{itemize}
            \item powtórzenia zdarzenia występują niezależnie od siebie,
            \item intensywność wystąpień $r>0$, czyli średnia liczba
                wystąpień w jednostce czasu jest stała,
            \item w danej chwili może zajść co najwyżej jedno powtórzenie,
        \end{itemize}
        to zmienna ma rozkład Poissona z parametrem $\lambda=rt>0$
        \[
            N \sim Pois(\lambda).
        \]
        Wówczas
        \[
            \mathcal{S}=\mathbb{N} \cup \{0\}
        \]
        \[
            p(k)=\frac{e^{-\lambda}\lambda^k}{k!}
        \]
        \[
            k\in \mathcal{S}
        \]
        oraz
        \[
            \mu=\lambda
        \]
        \[
            \sigma^2=\lambda
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{poissona.png}
            \caption{Funkcja prawdopodobieństwa w rozkładzie Poissona.}
        \end{figure}
    \end{definition}
    \begin{theorem}[Twierdzenie Poissona]
        Niech $X_n$ będzie ciągiem zmiennych losowych takich, że
        \[
            X_n \sim Binom(n,\theta_n),
        \]
        gdzie $\theta_n$ jest takim ciągiem, że
        \[
            \lim_{n \to \infty} n\theta_n=\lambda
        \]
        dla pewnej liczby $\lambda>0$. Wówczas
        \[
            \lim_{n \to \infty} P(X_n=k)=\frac{e^{-\lambda}\lambda^k}{k!}.
        \]
    \end{theorem}
    
    \subsection{Rozkłady ciągłe}
    \begin{definition}[Rozkład jednostajny]
        Mówimy, że zmienna losowa $X$ ma rozkład jednostajny na przedziale
        $[a,b]$ jeśli jej gęstość wyraża się wzorem
        \[
            f(x)=
            \begin{cases}
                \frac{1}{b-a} & ,x\in[a,b] \\
                0 & ,x \notin [a,b]
            \end{cases}
        \]
        zapisujemy
        \[
            X \sim \mathcal{U}(a,b).
        \]
        Wówczas
        \[
            \mu=\frac{a+b}{2}
        \]
        \[
            \sigma^2=\frac{(b-a)^2}{12}
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{jednostajny.png}
            \caption{Funkcja gęstości w rozkładzie jednostajnym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład wykładniczy]
        Niech $T$ będzie zmienną modelującą czas oczekiwania na pierwsze
        zdarzenie w ciągu zdarzeń takim, że ich liczba w przedziale $[0,t]$
        opisana jest przez zmienną $X$ o rozkładzie Poissona z patametrem
        $\lambda$. Mówimy wtedy, że $T$ ma rozkład wykładniczy z parametrem
        $\lambda$
        \[
            T \sim Exp(\lambda)
        \]
        Gęstość ma postać
        \[
            f(t)=
            \begin{cases}
                0 & ,t<0 \\
                \lambda e^{-\lambda t} & ,t \geq 0.
            \end{cases}
        \]
        Wówczas
        \[
            \mu=\frac{1}{\lambda}
        \]
        \[
            \sigma^2=\frac{1}{\lambda^2}
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{wykladniczy.png}
            \caption{Funkcja gęstości w rozkładzie wykładniczym.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład gamma]
        Mówimy, że zmienna losowa $X$ ma rozkład gamma z parametrami
        $s>0$ i $r>0$
        \[
            X \sim Gamma(s,r)
        \]
        jeśli jej gęstość wyraża się wzorem
        \[
            f(x)=
            \begin{cases}
                0 & ,x<0 \\
                \frac{r^s}{\Gamma(s)}x^{s-1}e^{-rx} & ,x \geq 0
            \end{cases}
        \]
        gdzie $\Gamma:(0,\infty) \rightarrow (0,\infty)$ jest tzw.
        funkcją Eulera
        \[
            \Gamma(s)=\int_{0}^{\infty}x^{s-1}e^{-x}dx.
        \]
        Jest rozkładem ogólniejszym niż rozkład wykładniczy,
        w szczególności
        \[
            Gamma(1,r)=Exp(r).
        \]
        Własności funkcji Eulera:
        \begin{enumerate}
            \item $\Gamma(s+1)=s\Gamma(s)$
            \item Jeśli $n\in \mathbb{N}$, to $\Gamma(n+1)=n!$
            \item $\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}$
            \item $\int_{0}^{\infty}x^{s-1}e^{-rx}dx=\frac{\Gamma(s)}{r^s}$
        \end{enumerate}
        Wielkości opisujące rozkład gamma:
        \[
            \mu=\frac{s}{r}
        \]
        \[
            \sigma^2=\frac{s}{r^2}
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{gamma_r.png}
            \caption{Funkcja gęstości w rozkładzie gamma dla ustalonego $r$.}
        \end{figure}
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{gamma_s.png}
            \caption{Funkcja gęstości w rozkładzie gamma dla ustalonego $s$.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład $\chi^2$]
        Szczególnym przypadkiem rozkładu gamma dla $s=\frac{n}{2}$
        i $r=\frac{1}{2}$ jest rozkład $\chi^2$ o $n$ stopniach swobody
        \[
            \chi^2(n)=Gamma\left(\frac{n}{2},\frac{1}{2}\right)
        \]
        zatem gęstość tego rozkładu wyraża się wzorem
        \[
            f(x)=
            \begin{cases}
                0 & ,x<0 \\
                \frac{1}{(\sqrt{2})^n\Gamma\left(\frac{n}{2}\right)}
                x^{\frac{n}{2}-1}e^{-\frac{x}{2}} & ,x\geq 0
            \end{cases}
        \]
        Wielkości opisujące rozkład $\chi^2$:
        \[
            \mu=n
        \]
        \[
            \sigma^2=2n
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{chi2.png}
            \caption{Funkcja gęstości w rozkładzie $\chi^2$.}
        \end{figure}
    \end{definition}
    \begin{definition}[Rozkład normalny]
        Mówimy, że zmienna losowa $X$ o gęstości $\phi_{\mu,\sigma}$ ma
        rozkład normalny z parametrami $\mu\in\mathbb{R}$ i $\sigma>0$
        \[
            X \sim \mathcal{N}(\mu,\sigma)
        \]
        jeśli
        \[
            \phi_{\mu,\sigma}(x)=\frac{1}{\sigma\sqrt{2\pi}}
            e^{-\frac{(x-\mu)^2}{2\sigma^2}}
        \]
        Wielkości opisujące rozkład normalny:
        \[
            \mathbb{E}(X)=\mu
        \]
        \[
            Var(X)=\sigma^2
        \]
        Rozkład $\mathcal{N}(0,1)$ nazywamy standardowym rozkładem
        normalnym. Jeśli $X \sim \mathcal{N}(\mu,\sigma)$, to
        \[
            X=\frac{X-\mu}{\sigma} \sim \mathcal{N}(0,1)
        \]
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{normalny_mu.png}
            \caption{Funkcja gęstości w rozkładzie normalnym
                dla ustalonego $\mu$.}
        \end{figure}
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{normalny_sigma.png}
            \caption{Funkcja gęstości w rozkładzie normalnym
                dla ustalonego $\sigma$.}
        \end{figure}
    \end{definition}

    \section{Zmienne losowe wielowymiarowe}
    Zmienna $(X,Y)$ o gęstości $f_{X,Y}(x,y)$ ma rozkłady brzegowe
    \[
        f_X(x)=\int_{-\infty}^{\infty}f_{X,Y}(x,y)dy
    \]
    \[
        f_Y(y)=\int_{-\infty}^{\infty}f_{X,Y}(x,y)dx
    \]
    rozkłady warunkowe
    \[
        f_{X|Y}(x|y)=\frac{f_{X,Y}(x,y)}{f_Y(y)}
    \]
    \[
        f_{Y|X}(y|x)=\frac{f_{X,Y}(x,y)}{f_X(x)}
    \]
    wartość oczekiwana
    \[
        \mathbb{E}[XY]=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
        xyf_{X,Y}(x,y)dxdy
    \]
    \[
        \mathbb{E}X=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
        xf_{X,Y}(x,y)dxdy
    \]
    \[
        \mathbb{E}X=\int_{-\infty}^{\infty}xf_X(x)dx
    \]
    kowariancja
    \[
        Cov(X,Y)=\mathbb{E}[(X-\mathbb{E}X)(Y-\mathbb{E}Y)]=
        \mathbb{E}[XY]-\mathbb{E}X\mathbb{E}Y
    \]
    współczynnik korelacji
    \[
        \rho_{X,Y}=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}
    \]

    \section{Wnioskowanie statystyczne}
    \subsection{Podstawy wnioskowania statystycznego}
    \begin{definition}[Model statystyczny]
        Modelem statystycznym nazywamy parę
        \[
            (\mathcal{X},\mathcal{P})
        \]
        gdzie $\mathcal{P}$ jest rodziną rozkładów prawdopodobieństwa na
        zbiorze $\mathcal{X}$. Zazwyczaj przyjmuje się, że
        \[
            \mathcal{P}=\{P_\theta :\theta \in \Theta\}
        \]
        dla pewnego zbioru $\Theta$ dopuszczalnych wartości parametrów
        modelu $\theta$.
    \end{definition}
    \begin{definition}[Prosta próba losowa]
        Prostą próbą losową o liczności $n$ z rozkładu $P_\theta$ nazywamy
        ciąg niezależnych zmiennych losowych $X_1,X_2,\ldots,X_n$ takich, że
        \[
            X_i \sim P_\theta
        \]
        dla każdego $i=1,2,\ldots,n$. Jeśli $X_1,X_2,\ldots,X_n$ jest prostą
        próbą losową, to ciąg wartości $x_1,x_2,\ldots,x_n\in \mathbb{R}$
        takich, że
        \[
            X_1(\omega)=x_1,X_2(\omega)=x_2,\ldots,X_n(\omega)=x_n
        \]
        dla pewnego $\omega$ nazywamy \textbf{realizacją prostej próby
        losowej} $X_1,X_2,\ldots,X_n$.
    \end{definition}

    \subsection{Statystyki}
    \begin{definition}[Statystyka]
        Statystyką nazywa się zmienną losową będącą funkcją prostej próby
        losowej
        \[
            T(X_1,X_2,\ldots,X_n).
        \]
        Funkcja $T$ używana do konstrukcji statystyki musi przyjmować
        listę argumentów dowolnej długości.
    \end{definition}
    \begin{definition}[Średnia w prostej próbie losowej]
        Jest to statystyka dana wzorem
        \[
            \bar{X}=\bar{X_n}-\frac{X_1+X_2+\ldots+X_n}{n}.
        \]
        Jeśli
        \[
            X_i \sim \mathcal{N}(\mu,\sigma)
        \]
        to korzystając z własności rozkładu normalnego otrzymujemy
        \[
            \bar{X} \sim \mathcal{N}\left(\mu,\frac{\sigma}{\sqrt{n}}\right).
        \]
    \end{definition}
    \begin{definition}[Wariancja w prostej próbie losowej]
        Jest to statystyka dana wzorem
        \[
            S^2=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_i-\bar{X}\right)^2.
        \]
    \end{definition}
    \begin{theorem}[Centralne Twierdzenie Graniczne]
        Niech $X_n$ będzie ciągiem niezależnych zmiennych losowych o tym
        samym rozkładzie ze skończoną średnią $\mu$ i skończoną, dodatnią
        wariancją $\sigma^2$. Wtedy dla dużych $n$ rozkład $\bar{X}$ jest
        w przybliżeniu równy rozkładowi normalnemu
        \[
            \bar{X} \approx \mathcal{N}(\mu,\frac{\sigma}{\sqrt{n}})
        \]
        Natomiast dla sumy takich zmiennych losowych mamy
        \[
            \sum_{i=1}^{n} X_i \approx \mathcal{N}(n\mu,\sigma\sqrt{n})
        \]
    \end{theorem}

    \subsection{Estymatory}
    \begin{definition}[Estymator punktowy]
        Niech $\theta$ będzie parametrem lub innym wskaźnikiem liczbowym
        pewnego rozkładu prawdopodobieństwa. Estymatorem $\theta$ nazywa
        się statystykę
        \[
            \hat{\theta}(X_1,X_2,\ldots,X_n)
        \]
        służącą do wyznaczenia przybliżonej wartości $\theta$. Jeśli
        $x_1,x_2,\ldots,x_n$ jest realizacją prostej próby losowej
        $X_1,X_2,\ldots,X_n$, to liczbę
        \[
            \hat{\theta}(x_1,x_2,\ldots,x_n)
        \]
        nazywa się \textbf{wartością estymatora} albo
        \textbf{estymatą}.
    \end{definition}
    \begin{definition}[Funkcja wiarygodności]
        Niech $X_1,X_2,\ldots,X_n$ będzie prostą próbą losową,
        a $x_1,x_2,\ldots,x_n$ jej realizacją. Funkcją wiarygodności dla
        modelu statystycznego $\mathcal{P}=\{P_\theta :\theta \in \Theta\}$,
        jeśli $P_\theta$ jest rozkładem ciągłym o gęstości $f_\theta$,
        nazywamy funkcję
        \[
            \mathcal{L}(\theta |x_1,x_2,\ldots,x_n)=f_\theta(x_1) \cdot
            f_\theta(x_2) \cdot \ldots \cdot f_\theta(x_n)
        \]
        natomiast jeśli $P_\theta$ jest rozkładem dyskretnym z funkcją
        prawdopodobieństwa $p_\theta$, to
        \[
            \mathcal{L}(\theta |x_1,x_2,\ldots,x_n)=p_\theta(x_1) \cdot
            p_\theta(x_2) \cdot \ldots \cdot p_\theta(x_n).
        \]
        Ze względów obliczeniowych często rozważa się logarytmiczną
        funkcję wiarygodności
        \[
            l(\theta |x_1,x_2,\ldots,x_n)=\ln\mathcal{L}
            (\theta |x_1,x_2,\ldots,x_n)
        \]
        dla rozkładów ciągłych mamy
        \[
            l(\theta |x_1,x_2,\ldots,x_n)=\ln f_\theta(x_1)+\ln
            f_\theta(x_2)+\ldots+\ln f_\theta(x_n)
        \]
        a dla rozkładów dyskretnych
        \[
            l(\theta |x_1,x_2,\ldots,x_n)=\ln p_\theta(x_1)+\ln
            p_\theta(x_2)+\ldots+\ln p_\theta(x_n)
        \]
    \end{definition}
    \begin{definition}[Estymator największej wiarygodności (MLE)]
        Estymatorem największej wiarygodności nazywamy funkcję
        $\hat{\theta}$, która przy ustalonych danych
        $x=(x_1,x_2,\ldots,x_n)$ maksymalizuje wartość funkcji
        wiarygodności, albo wartość logarytmicznej funkcji
        wiarygodności. Jeśli funkcja wiarygodności jest różniczkowalna
        względem
        \[
            \theta=(\theta_1,\theta_2,\ldots,\theta_k)
        \]
        dla dowolnego $x=(x_1,x_2,\ldots,x_n)$, to MLE można czasem
        wyznaczyć analitycznie obliczając pochodne względem parametrów
        rozkładu i rozwiązując układ równań
        \[
            \begin{cases}
                \frac{\partial}{\partial\theta_1}\mathcal{L}(\theta|x)=0\\
                \frac{\partial}{\partial\theta_2}\mathcal{L}(\theta|x)=0\\
                \vdots \\
                \frac{\partial}{\partial\theta_k}\mathcal{L}(\theta|x)=0
            \end{cases}
        \]
        albo
        \[
            \begin{cases}
                \frac{\partial}{\partial\theta_1}l(\theta|x)=0 \\
                \frac{\partial}{\partial\theta_2}l(\theta|x)=0 \\
                \vdots \\
                \frac{\partial}{\partial\theta_k}l(\theta|x)=0
            \end{cases}
        \]
    \end{definition}
    \begin{definition}[Estymator metody momentów]
        
    \end{definition}

    \subsection{Przedziały ufności}
    TODO

    \subsection{Testowanie hipotez}
    \begin{definition}[Hipoteza statystyczna]
        Rozważamy model statystyczny
        $\mathcal{P}=\{P_\theta :\theta\in\Theta\}$. Hipotezą
        statystyczną nazywamy dowolny niepusty podzbiór $\mathcal{P}$.
        W praktyce wyróżniamy jedną hipotezę zwaną \textbf{hipotezą zerową}
        ($H_0$), która podlega weryfikacji, natomiast
        $H_1=\mathcal{P}\setminus H_0$ nazywamy \textbf{hipotezą
        alternatywną}.
    \end{definition}
    \begin{definition}[Zbiór krytyczny testu]
        Statystykę $U$ TODO
    \end{definition}
    \begin{definition}[p-wartość]
        p-wartość to, dla zaobserwowanej wartości statystyki testowej,
        najmniejszy poziom istotności, przy którym ta wartość prowadzi do
        odrzucenia hipotezy zerowej. Inaczej, dla poziomu istotności
        $\alpha$ oraz p-wartości $p$, jeżeli
        \begin{align*}
            & p>\alpha \Rightarrow \text{brak podstaw do odrzucenia }H_0 \\
            & p\leq\alpha \Rightarrow \text{odrzucamy }H_0
        \end{align*}
    \end{definition}
    \begin{theorem}[Test dla wartości oczekiwanej przy znanej wariancji]
        Mamy $\mathcal{P}=\{\mathcal{N}(\mu,\sigma):\mu\in\mathbb{R}\}$ dla
        ustalonego $\sigma>0$. Ustalamy hipotezy
        \[
            H_0:\mu=\mu_0
        \]
        \[
            H_1:\mu\neq\mu_0.
        \]
        Jako statystykę testową bierzemy
        \[
            Z=\frac{\bar{X}-\mu_0}{\frac{\sigma}{\sqrt{n}}}
        \]
        oraz przyjmujemy zbiór krytyczny na poziomie istotności $\alpha$
        \[
            C=\left(-\infty,-z_{1-\frac{\alpha}{2}}\right] \cup
            \left[z_{1-\frac{\alpha}{2}},\infty\right)
        \]
        p-wartość dla dwustronnej hipotezy alternatywnej wynosi
        \[
            p(z)=2(1-\Phi(|z|))
        \]
        gdzie $\Phi$ jest dystrybuantą rozkładu normalnego.
    \end{theorem}
    \begin{theorem}[Test dla wartości oczekiwanej przy nieznanej wariancji]
        Jako statystykę testową bierzemy
        \[
            T=\frac{\bar{X}-\mu_0}{\frac{S}{\sqrt{n}}}
        \]
        oraz przyjmujemy zbiór krytyczny na poziomie istotności $\alpha$ dla
        dwustronnej hipotezy alternatywnej
        \[
            C=\left(-\infty,-t_{1-\frac{\alpha}{2},n-1}\right] \cup
            \left[t_{1-\frac{\alpha}{2},n-1},\infty\right)
        \]
        p-wartość wynosi
        \[
            p(t)=2(1-F_{n-1}(|t|))
        \]
        gdzie $F_{n-1}$ jest dystrybuantą rozkładu $t_{n-1}$.
    \end{theorem}
    \begin{theorem}[Test dla wartości oczekiwanej z dwóch prób]
        Dla nieznanych, ale równych wariancji używamy statystyki
        \[
            T=\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}
                {S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}
        \]
        jeżeli wariancje są znane to
        \[
            T=\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}
                {\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_1^2}{n_2}}}
        \]
        Dla dwustronnej hipotezy alternatywnej
        \[
            \mu_1\neq\mu_2
        \]
    \end{theorem}
    \begin{theorem}[Test równości wariancji]
        
    \end{theorem}

    \section{Literatura}
    \begin{thebibliography}{9}
        \bibitem{Smołka} Smołka, M. (2026). Rachunek prawdopodobieństwa
        i statystyka. \textit{Wykłady prowadzone na Akademii
        Górniczo-Hutniczej w Krakowie}.
    \end{thebibliography}
\end{document}
